## Question 1
The sourcing team at the US headquarters of a global e-commerce company is preparing a spreadsheet of the new product catalog. The spreadsheet is saved on an Amazon Elastic File System (Amazon EFS) created in `us-east-1` region. The sourcing team counterparts from other AWS regions such as Asia Pacific and Europe also want to collaborate on this spreadsheet.

As a solutions architect, what is your recommendation to enable this collaboration with the LEAST amount of operational overhead?

1. The spreadsheet will have to be copied into Amazon EFS file systems of other AWS regions as Amazon EFS is a regional service and it does not allow access from other AWS regions

2. The spreadsheet will have to be copied in Amazon S3 which can then be accessed from any AWS region

3. The spreadsheet data will have to be moved into an Amazon RDS for MySQL database which can then be accessed from any AWS region

4. The spreadsheet on the Amazon Elastic File System (Amazon EFS) can be accessed in other AWS regions by using an inter-region VPC peering connection

---

## Question 2

The engineering team at an in-home fitness company is evaluating multiple in-memory data stores with the ability to power its on-demand, live leaderboard. The company's leaderboard requires high availability, low latency, and real-time processing to deliver customizable user data for the community of users working out together virtually from the comfort of their home.

As a solutions architect, which of the following solutions would you recommend? (Select two)

1. Power the on-demand, live leaderboard using Amazon RDS for Aurora as it meets the in-memory, high availability, low latency requirements

2. Power the on-demand, live leaderboard using Amazon ElastiCache for Redis as it meets the in-memory, high availability, low latency requirements

3. Power the on-demand, live leaderboard using Amazon DynamoDB with DynamoDB Accelerator (DAX) as it meets the in-memory, high availability, low latency requirements

4. Power the on-demand, live leaderboard using Amazon Neptune as it meets the in-memory, high availability, low latency requirements

5. Power the on-demand, live leaderboard using Amazon DynamoDB as it meets the in-memory, high availability, low latency requirements

---

## Question 3
An Electronic Design Automation (EDA) application produces massive volumes of data that can be divided into two categories. The 'hot data' needs to be both processed and stored quickly in a parallel and distributed fashion. The 'cold data' needs to be kept for reference with quick access for reads and updates at a low cost.

Which of the following AWS services is BEST suited to accelerate the aforementioned chip design process?

1. Amazon EMR

2. Amazon FSx for Windows File Server

3. AWS Glue

4. Amazon FSx for Lustre

---

## Question 4

A gaming company is looking at improving the availability and performance of its global flagship application which utilizes User Datagram Protocol and needs to support fast regional failover in case an AWS Region goes down. The company wants to continue using its own custom Domain Name System (DNS) service.

Which of the following AWS services represents the best solution for this use-case?

1. Amazon Route 53

2. Amazon CloudFront

3. AWS Global Accelerator

4. AWS Elastic Load Balancing (ELB)

---

## Question 5

The engineering team at a data analytics company has observed that its flagship application functions at its peak performance when the underlying Amazon Elastic Compute Cloud (Amazon EC2) instances have a CPU utilization of about 50%. The application is built on a fleet of Amazon EC2 instances managed under an Auto Scaling group. The workflow requests are handled by an internal Application Load Balancer that routes the requests to the instances.

As a solutions architect, what would you recommend so that the application runs near its peak performance state?

1. Configure the Auto Scaling group to use a Amazon Cloudwatch alarm triggered on a CPU utilization threshold of 50%

2. Configure the Auto Scaling group to use simple scaling policy and set the CPU utilization as the target metric with a target value of 50%

3. Configure the Auto Scaling group to use step scaling policy and set the CPU utilization as the target metric with a target value of 50%

4. Configure the Auto Scaling group to use target tracking policy and set the CPU utilization as the target metric with a target value of 50%

---

## Question 6
A file-hosting service uses Amazon Simple Storage Service (Amazon S3) under the hood to power its storage offerings. Currently all the customer files are uploaded directly under a single Amazon S3 bucket. The engineering team has started seeing scalability issues where customer file uploads have started failing during the peak access hours with more than 5000 requests per second.

Which of the following is the MOST resource efficient and cost-optimal way of addressing this issue?

1. Change the application architecture to create a new Amazon S3 bucket for each customer and then upload each customer's files directly under the respective buckets

2. Change the application architecture to use Amazon Elastic File System (Amazon EFS) instead of Amazon S3 for storing the customers' uploaded files

3. Change the application architecture to create customer-specific custom prefixes within the single Amazon S3 bucket and then upload the daily files into those prefixed locations

4. Change the application architecture to create a new Amazon S3 bucket for each day's data and then upload the daily files directly under that day's bucket

---

## Question 7
A telecom company operates thousands of hardware devices like switches, routers, cables, etc. The real-time status data for these devices must be fed into a communications application for notifications. Simultaneously, another analytics application needs to read the same real-time status data and analyze all the connecting lines that may go down because of any device failures.

As an AWS Certified Solutions Architect – Associate, which of the following solutions would you suggest, so that both the applications can consume the real-time status data concurrently?

1. Amazon Simple Queue Service (SQS) with Amazon Simple Email Service (Amazon SES)

2. Amazon Simple Notification Service (SNS)

3. Amazon Simple Queue Service (SQS) with Amazon Simple Notification Service (SNS)

4. Amazon Kinesis Data Streams

---

## Question 8
A company uses Amazon DynamoDB as a data store for various kinds of customer data, such as user profiles, user events, clicks, and visited links. Some of these use-cases require a high request rate (millions of requests per second), low predictable latency, and reliability. The company now wants to add a caching layer to support high read volumes.

As a solutions architect, which of the following AWS services would you recommend as a caching layer for this use-case? (Select two)

1. Amazon Relational Database Service (Amazon RDS)

2. Amazon OpenSearch Service

3. Amazon ElastiCache

4. Amazon Redshift

5. Amazon DynamoDB Accelerator (DAX)

---

## Question 9
The solo founder at a tech startup has just created a brand new AWS account. The founder has provisioned an Amazon EC2 instance 1A which is running in AWS Region A. Later, he takes a snapshot of the instance 1A and then creates a new Amazon Machine Image (AMI) in Region A from this snapshot. This AMI is then copied into another Region B. The founder provisions an instance 1B in Region B using this new AMI in Region B.

At this point in time, what entities exist in Region B?

1. 1 Amazon EC2 instance and 2 AMIs exist in Region B

2. 1 Amazon EC2 instance and 1 snapshot exist in Region B

3. 1 Amazon EC2 instance, 1 AMI and 1 snapshot exist in Region B

4. 1 Amazon EC2 instance and 1 AMI exist in Region B

---

## Question 10
A company is in the process of migrating its on-premises SMB file shares to AWS so the company can get out of the business of managing multiple file servers across dozens of offices. The company has 200 terabytes of data in its file servers. The existing on-premises applications and native Windows workloads should continue to have low latency access to this data which needs to be stored on a file system service without any disruptions after the migration. The company also wants any new applications deployed on AWS to have access to this migrated data.

Which of the following is the best solution to meet this requirement?

1. Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon EFS. The applications deployed on AWS can access this data directly from Amazon EFS

2. Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon FSx for Windows File Server. The applications deployed on AWS can access this data directly from Amazon FSx in AWS

3. Use Amazon Storage Gateway’s File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon FSx for Windows File Server. The applications deployed on AWS can access this data directly from Amazon FSx in AWS

4. Use AWS Storage Gateway’s File Gateway to provide low-latency, on-premises access to fully managed file shares in Amazon S3. The applications deployed on AWS can access this data directly from Amazon S3

---

## Question 11
A logistics company is building a multi-tier application to track the location of its trucks during peak operating hours. The company wants these data points to be accessible in real-time in its analytics platform via a REST API. The company has hired you as an AWS Certified Solutions Architect Associate to build a multi-tier solution to store and retrieve this location data for analysis.

Which of the following options addresses the given use case?

1. Leverage Amazon QuickSight with Amazon Redshift

2. Leverage Amazon Athena with Amazon S3

3. Leverage Amazon API Gateway with AWS Lambda

4. Leverage Amazon API Gateway with Amazon Kinesis Data Analytics

---

## Question 12
A junior scientist working with the Deep Space Research Laboratory at NASA is trying to upload a high-resolution image of a nebula into Amazon S3. The image size is approximately 3 gigabytes. The junior scientist is using Amazon S3 Transfer Acceleration (Amazon S3TA) for faster image upload. It turns out that Amazon S3TA did not result in an accelerated transfer.

Given this scenario, which of the following is correct regarding the charges for this image transfer?

1. The junior scientist only needs to pay Amazon S3 transfer charges for the image upload

2. The junior scientist only needs to pay S3TA transfer charges for the image upload

3. The junior scientist needs to pay both S3 transfer charges and S3TA transfer charges for the image upload

4. The junior scientist does not need to pay any transfer charges for the image upload

---

## Question 13
An ivy-league university is assisting NASA to find potential landing sites for exploration vehicles of unmanned missions to our neighboring planets. The university uses High Performance Computing (HPC) driven application architecture to identify these landing sites.

Which of the following Amazon EC2 instance topologies should this application be deployed on?

1. The Amazon EC2 instances should be deployed in a partition placement group so that distributed workloads can be handled effectively

2. The Amazon EC2 instances should be deployed in an Auto Scaling group so that application meets high availability requirements

3. The Amazon EC2 instances should be deployed in a cluster placement group so that the underlying workload can benefit from low network latency and high network throughput

4. The Amazon EC2 instances should be deployed in a spread placement group so that there are no correlated failures

---

## Question 14
Which of the following feature of an Amazon S3 bucket can only be suspended and not disabled once it have been enabled?

1. Static Website Hosting

2. Server Access Logging

3. Requester Pays

4. Versioning

---

## Question 15
A research group runs its flagship application on a fleet of Amazon EC2 instances for a specialized task that must deliver high random I/O performance. Each instance in the fleet would have access to a dataset that is replicated across the instances by the application itself. Because of the resilient application architecture, the specialized task would continue to be processed even if any instance goes down, as the underlying application would ensure the replacement instance has access to the required dataset.

Which of the following options is the MOST cost-optimal and resource-efficient solution to build this fleet of Amazon EC2 instances?

1. Use Amazon Elastic Block Store (Amazon EBS) based EC2 instances

2. Use Instance Store based Amazon EC2 instances

3. Use Amazon EC2 instances with access to Amazon S3 based storage

4. Use Amazon EC2 instances with Amazon EFS mount points

---

## Question 16
A software engineering intern at an e-commerce company is documenting the process flow to provision Amazon EC2 instances via the Amazon EC2 API. These instances are to be used for an internal application that processes Human Resources payroll data. He wants to highlight those volume types that cannot be used as a boot volume.

Can you help the intern by identifying those storage volume types that CANNOT be used as boot volumes while creating the instances? (Select two)

1. Instance Store

2. General Purpose Solid State Drive (gp2)

3. Provisioned IOPS Solid state drive (io1)

4. Cold Hard disk drive (sc1)

5. Throughput Optimized Hard disk drive (st1)

---

## Question 17
The product team at a startup has figured out a market need to support both stateful and stateless client-server communications via the application programming interface (APIs) developed using its platform. You have been hired by the startup as a solutions architect to build a solution to fulfill this market need using Amazon API Gateway.

Which of the following would you identify as correct?

1. Amazon API Gateway creates RESTful APIs that enable stateful client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full-duplex communication between client and server

2. Amazon API Gateway creates RESTful APIs that enable stateless client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateless, full-duplex communication between client and server

3. Amazon API Gateway creates RESTful APIs that enable stateful client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server

4. Amazon API Gateway creates RESTful APIs that enable stateless client-server communication and Amazon API Gateway also creates WebSocket APIs that adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server

---

## Question 18
A gaming company is developing a mobile game that streams score updates to a backend processor and then publishes results on a leaderboard. The company has hired you as an AWS Certified Solutions Architect Associate to design a solution that can handle major traffic spikes, process the mobile game updates in the order of receipt, and store the processed updates in a highly available database. The company wants to minimize the management overhead required to maintain the solution.

Which of the following will you recommend to meet these requirements?

1. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue which uses a fleet of Amazon EC2 instances (with Auto Scaling) to process these updates in the Amazon SQS queue and then store these processed updates in an Amazon RDS MySQL database

2. Push score updates to Amazon Kinesis Data Streams which uses an AWS Lambda function to process these updates and then store these processed updates in Amazon DynamoDB

3. Push score updates to Amazon Kinesis Data Streams which uses a fleet of Amazon EC2 instances (with Auto Scaling) to process the updates in Amazon Kinesis Data Streams and then store these processed updates in Amazon DynamoDB

4. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic, subscribe an AWS Lambda function to this Amazon SNS topic to process the updates and then store these processed updates in a SQL database running on Amazon EC2 instance

---

## Question 19
A retail company's dynamic website is hosted using on-premises servers in its data center in the United States. The company is launching its website in Asia, and it wants to optimize the website loading times for new users in Asia. The website's backend must remain in the United States. The website is being launched in a few days, and an immediate solution is needed.

What would you recommend?

1. Use Amazon CloudFront with a custom origin pointing to the DNS record of the website on Amazon Route 53

2. Migrate the website to Amazon S3. Use S3 cross-region replication (S3 CRR) between AWS Regions in the US and Asia

3. Leverage a Amazon Route 53 geo-proximity routing policy pointing to on-premises servers

4. Use Amazon CloudFront with a custom origin pointing to the on-premises servers

---

## Question 20
A data analytics company measures what the consumers watch and what advertising they’re exposed to. This real-time data is ingested into its on-premises data center and subsequently, the daily data feed is compressed into a single file and uploaded on Amazon S3 for backup. The typical compressed file size is around 2 gigabytes.

Which of the following is the fastest way to upload the daily compressed file into Amazon S3?

1. FTP the compressed file into an Amazon EC2 instance that runs in the same region as the Amazon S3 bucket. Then transfer the file from the Amazon EC2 instance into the Amazon S3 bucket

2. Upload the compressed file using multipart upload

3. Upload the compressed file using multipart upload with Amazon S3 Transfer Acceleration (Amazon S3TA)

4. Upload the compressed file in a single operation

---

## Question 21
The engineering team at an e-commerce company wants to establish a dedicated, encrypted, low latency, and high throughput connection between its data center and AWS Cloud. The engineering team has set aside sufficient time to account for the operational overhead of establishing this connection.

As a solutions architect, which of the following solutions would you recommend to the company?

1. Use AWS Direct Connect to establish a connection between the data center and AWS Cloud

2. Use AWS site-to-site VPN to establish a connection between the data center and AWS Cloud

3. Use AWS Transit Gateway to establish a connection between the data center and AWS Cloud

4. Use AWS Direct Connect plus virtual private network (VPN) to establish a connection between the data center and AWS Cloud

---

## Question 22
A large financial institution operates an on-premises data center with hundreds of petabytes of data managed on Microsoft’s Distributed File System (DFS). The CTO wants the organization to transition into a hybrid cloud environment and run data-intensive analytics workloads that support DFS.

Which of the following AWS services can facilitate the migration of these workloads?

1. Amazon FSx for Windows File Server

2. Microsoft SQL Server on AWS

3. AWS Directory Service for Microsoft Active Directory (AWS Managed Microsoft AD)

4. Amazon FSx for Lustre